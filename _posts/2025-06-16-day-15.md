---
layout: post
title: "Day 15 - Meta-Adv Model Results"
date: 2025-06-16
author: Pedro Contreras
permalink: /day15.html
tags: ["Cybersecurity", "Machine Learning"]

what_i_learned: |
  Over the weekend I left my large code running to get better or improved accuracy for detecting the adversarial attacks and it only improved by 0.04%. Most of today I spent trying to improve my model by running small versions to see where the issue lies, and I was able to understand how meta-learning actually works, where the model is learning how to learn by training it with tasks and then giving it tasks it has not seen before in order to improve its overall accuracy on detecting these attacks. Most of the errors I ran into were mainly just library function erros because I am using CoLab, so I had to tweak the code in order for it to function properly. I was able to find the error in the mix of attacks within the dataset and once i wa sable to fix that, the accuracy started improving. 
  
blockers: |
  A lot of the errors were tedious, since I am using Colab it wasn't able to run certain functions or call certain attacks and so I had to work my way around that. 
reflection: |
  The debugging issues were more so about how the code was structured. Once I was able to replicate more or less how the model in the paper is, I was finally able to get better results and so it made it a lot better. Overall today I was able to realize how important the way the code is built matters and the software im using has things that need to be worked around. I feel more confident in my ability to debug code and understand how to adjust the model.

---
