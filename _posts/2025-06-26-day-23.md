---
layout: post
title: "Day 23 - GPU Update of Meta Adv"
date: 2025-06-26
author: Pedro Contreras
permalink: /day23.html
tags: ["Cybersecurity", "Machine Learning"]

what_i_learned: |
  Today I came back to see my CPU model still running even after it having ran all night. It made it to about 16, and right befor our meeting with Dr. Cole it stopped running so I was not able to recover the data was lost. During the meeting, we spoke about what we have in our current presentation and he gave us some very helpgul feedback in regards to how to present and what to include in our slides. After lunch, I ended up just paying for more GPU units on Colab in order to make actual progtress because CPU would take forever to run what I needed it to run. I was able to test a couple of versions, some with meta-learning and with specific steps that are supposed to replicate the paper. The meta-loss was not reducing it was stuck at 2.3, and no matter what I tried it would not go down. So for now, I am running the baseline (originally made for CPU) set up for L4 GPU and am raising the epochs to 400, instead of the original 20 it has, and using the full CIFAR-10 dataset. I will leave it running for right now and tomorrow I will try to use the same model but implement features that the paper has. 
  
blockers: |
  The model stopped running after like 21 hours of run time and it was not able to finish the full 20 epochs.
  
reflection: |
  The model having stopped annoyed me because it was already running slow so it was just a big waste of time. I did notice how much the meta loss was decreasing a lot so I am wondering what the end result would have been. The feedback from Dr. Cole was very helpful, especially with what we had on our slides. I want to make progress and thee CPU thing set me back so I am just trying to see now what works best while staying true to the model in the paper. 
---
