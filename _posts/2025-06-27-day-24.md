---
layout: post
title: "Day 24 - GPU Update of Meta Adv"
date: 2025-06-27
author: Pedro Contreras
permalink: /day24.html
tags: ["Cybersecurity", "Machine Learning"]

what_i_learned: |
  Today I came back to the baseline model I replicated but set up for GPU that I had left running overnight and the meta-loss actually got really low, to about 0.1. After that I read through the paper myself and used the exact steps they followed in order to come up with a model. Their model has 1000 tasks for a large number of epochs, so I attmpted to follow the same way they did and do it using A100 GPU which is better than the L4. This will take a lot longer because of how many tasks it is set up with. I also tried copying how they split up their attacks during training for each task. Ultimately I think this model will be the one to be able to fully run. We also worked on our weekly report video. 
  
blockers: |
  Long run times, even with the best GPU. 
  
reflection: |
  Te basline set up for GPU was the lowest Meta-loss I have came up with so I was proud of that. I knew this project was going to need a lot of power to run, but today I was able to grasp how much exactly considering this model that follows the paper's guidelines. I had to run through it a couple of times because this model has so much to account for, in terms of its attacks, the inner steps, the hyper-paremeters, etc. The A100 GPU is supposed to be the best GPU for this but im noticing it eat up the units I have left on Colab, so I hope this is enough for it to fully run and be able to make updates. 
---
